# RAG Knowledge System - éƒ¨ç½²æŒ‡å—

## é¡¹ç›®ç®€ä»‹

åŸºäº FastAPI + LlamaIndex çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿï¼Œæ”¯æŒæ–‡æ¡£å‘é‡åŒ–æ£€ç´¢å’Œæ™ºèƒ½é—®ç­”ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ“„ æ–‡æ¡£ä¸Šä¼ å’Œå‘é‡åŒ–å­˜å‚¨
- ğŸ” è¯­ä¹‰æ£€ç´¢å’Œç›¸ä¼¼åº¦åŒ¹é…
- ğŸ¤– åŸºäº OpenAI çš„æ™ºèƒ½é—®ç­”
- ğŸ’¾ å…ƒæ•°æ®å’Œå‘é‡æ•°æ®åˆ†ç¦»å­˜å‚¨

### æŠ€æœ¯æ ˆ
- **åç«¯æ¡†æ¶**: FastAPI 0.109+
- **AI æ¡†æ¶**: LlamaIndex 0.10+
- **LLM/Embedding**: OpenAI (GPT + text-embedding-ada-002)
- **å‘é‡æ•°æ®åº“**: Milvus 2.3.13
- **å…³ç³»æ•°æ®åº“**: MySQL 8.0
- **ç¼“å­˜å±‚**: Redis 7.2
- **å…¨æ–‡æœç´¢**: Elasticsearch 8.11

## æ¶æ„ç»„ä»¶

### ä¸­é—´ä»¶æœåŠ¡

| æœåŠ¡ | ç‰ˆæœ¬ | ç”¨é€” | çŠ¶æ€ |
|------|------|------|------|
| **MySQL** | 8.0 | å­˜å‚¨æ–‡ä»¶å…ƒæ•°æ®å’Œç»“æ„åŒ–æ•°æ® | âœ… å·²é›†æˆ |
| **Milvus** | 2.3.13 | å‘é‡æ•°æ®åº“ï¼Œå­˜å‚¨æ–‡æ¡£ embedding | âœ… å·²é›†æˆ |
| **Redis** | 7.2-alpine | ç¼“å­˜å’Œä¼šè¯ç®¡ç† | ğŸ”„ ä¸ºæœªæ¥åŠŸèƒ½é¢„ç•™ |
| **Elasticsearch** | 8.11.0 | å…¨æ–‡æœç´¢å¼•æ“ | ğŸ”„ ä¸ºæœªæ¥åŠŸèƒ½é¢„ç•™ |
| **MinIO** | 2023-03-20 | Milvus ä¾èµ–çš„å¯¹è±¡å­˜å‚¨ | âœ… å·²éƒ¨ç½² |
| **Etcd** | 3.5.5 | Milvus ä¾èµ–çš„å…ƒæ•°æ®ç®¡ç† | âœ… å·²éƒ¨ç½² |

### ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FastAPI åº”ç”¨                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   æ–‡ä»¶ä¸Šä¼     â”‚  â”‚   å‘é‡æ£€ç´¢    â”‚  â”‚   æ™ºèƒ½é—®ç­”    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                 â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  MySQL 8.0     â”‚ â”‚  Milvus    â”‚    â”‚  OpenAI API â”‚
    â”‚  (å…ƒæ•°æ®å­˜å‚¨)   â”‚ â”‚ (å‘é‡å­˜å‚¨)  â”‚    â”‚ (LLM/Embed) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Etcd + MinIO  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æœªæ¥æ‰©å±•ï¼ˆå·²éƒ¨ç½²æœåŠ¡ï¼‰:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Redis         â”‚    â”‚ Elasticsearch   â”‚
    â”‚  (ç¼“å­˜/ä¼šè¯)    â”‚    â”‚ (å…¨æ–‡æœç´¢)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

**æœåŠ¡å™¨è¦æ±‚ï¼š**
- Docker >= 20.10
- Docker Compose >= 2.0
- å¯ç”¨å†…å­˜ >= 4GBï¼ˆæ¨è 8GBï¼‰
- å¯ç”¨ç£ç›˜ >= 20GB

**å®‰è£… Dockerï¼ˆå¦‚æœªå®‰è£…ï¼‰ï¼š**

```bash
# Ubuntu/Debian
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# å®‰è£… docker-compose
sudo apt install docker-compose-plugin

# éªŒè¯å®‰è£…
docker --version
docker-compose --version
```

**CentOS/RHELï¼š**

```bash
# å®‰è£… Docker
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin

# å¯åŠ¨ Docker
sudo systemctl start docker
sudo systemctl enable docker
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

**å…‹éš†é¡¹ç›®åï¼Œé…ç½®ç¯å¢ƒå˜é‡ï¼š**

```bash
cd /path/to/rag_project

# .env æ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥ä¿®æ”¹æ•æ„Ÿä¿¡æ¯
vim .env
```

**å¿…é¡»ä¿®æ”¹çš„é…ç½®ï¼š**

```env
# ä¿®æ”¹æ•°æ®åº“å¯†ç ï¼ˆç”Ÿäº§ç¯å¢ƒå¿…é¡»ä½¿ç”¨å¼ºå¯†ç ï¼‰
DB_PASSWORD=your_secure_password_here
DB_ROOT_PASSWORD=your_root_password_here

# ä¿®æ”¹ Redis å¯†ç 
REDIS_PASSWORD=your_redis_password_here

# é…ç½® OpenAI API Keyï¼ˆå¿…éœ€ï¼‰
OPENAI_API_KEY=sk-your-actual-api-key
```

### 3. å¯åŠ¨æ‰€æœ‰æœåŠ¡

**å¯åŠ¨æ‰€æœ‰ä¸­é—´ä»¶ï¼ˆä¸å¯åŠ¨åç«¯åº”ç”¨ï¼‰ï¼š**

```bash
# ä»…å¯åŠ¨ä¸­é—´ä»¶æœåŠ¡
docker-compose up -d mysql_db milvus-standalone redis elasticsearch etcd minio

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker-compose logs -f
```

**é¢„æœŸè¾“å‡ºï¼š**

```
NAME                    STATUS              PORTS
rag_mysql              Up 30 seconds       0.0.0.0:3306->3306/tcp
milvus-standalone      Up 30 seconds       0.0.0.0:19530->19530/tcp, 0.0.0.0:9091->9091/tcp
rag_redis              Up (healthy)        0.0.0.0:6379->6379/tcp
rag_elasticsearch      Up (healthy)        0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp
milvus-etcd            Up 30 seconds       2379/tcp
milvus-minio           Up (healthy)        9000/tcp
```

**å¯åŠ¨åŒ…æ‹¬åç«¯åº”ç”¨åœ¨å†…çš„æ‰€æœ‰æœåŠ¡ï¼š**

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆåŒ…æ‹¬ FastAPI åç«¯ï¼‰
docker-compose up -d

# æŸ¥çœ‹åç«¯æ—¥å¿—
docker-compose logs -f backend
```

### 4. éªŒè¯æœåŠ¡å¯ç”¨æ€§

**æµ‹è¯• MySQLï¼š**

```bash
docker exec rag_mysql mysql -urag_user -p"$(grep DB_PASSWORD .env | cut -d'=' -f2)" -e "SELECT 1"
# é¢„æœŸè¾“å‡º: 1
```

**æµ‹è¯• Redisï¼š**

```bash
docker exec rag_redis redis-cli -a "$(grep REDIS_PASSWORD .env | cut -d'=' -f2)" ping
# é¢„æœŸè¾“å‡º: PONG
```

**æµ‹è¯• Elasticsearchï¼š**

```bash
curl -X GET "http://localhost:9200/_cluster/health?pretty"
# é¢„æœŸè¾“å‡º: JSON æ ¼å¼çš„é›†ç¾¤å¥åº·ä¿¡æ¯ï¼Œstatus ä¸º "green" æˆ– "yellow"
```

**æµ‹è¯• Milvusï¼š**

```bash
curl http://localhost:19530/healthz
# é¢„æœŸè¾“å‡º: å¥åº·çŠ¶æ€ä¿¡æ¯
```

---

## æœ¬åœ°ç”µè„‘è®¿é—®ä¸­é—´ä»¶

> **âš ï¸ é‡è¦è¯´æ˜ï¼š**
> - **æœåŠ¡å™¨ï¼ˆå½“å‰ä¸»æœºï¼‰**ï¼š10.112.15.13ï¼ˆè¿è¡Œ Docker æœåŠ¡çš„æœºå™¨ï¼‰
> - **å…¶ä»–ç”µè„‘**ï¼šéœ€è¦è¿æ¥åˆ°æœåŠ¡å™¨ä½¿ç”¨ä¸­é—´ä»¶çš„ç”µè„‘
> - **"æœ¬åœ°ç”µè„‘"** = "å…¶ä»–ç”µè„‘"ï¼ˆä¸æ˜¯æœåŠ¡å™¨æœ¬èº«ï¼‰

### è®¿é—®æ–¹å¼æ¦‚è§ˆ

| æœåŠ¡ | ä»å…¶ä»–ç”µè„‘è®¿é—®çš„åœ°å€ | è®¤è¯ä¿¡æ¯ | é»˜è®¤ç«¯å£ |
|------|---------------------|----------|---------|
| **MySQL** | `10.112.15.13:3306` | ç”¨æˆ·åï¼š`rag_user`<br/>å¯†ç ï¼šè§ `.env` | 3306 |
| **Redis** | `10.112.15.13:6379` | å¯†ç ï¼šè§ `.env` | 6379 |
| **Elasticsearch** | `10.112.15.13:9200` | æ— è®¤è¯ï¼ˆå¼€å‘æ¨¡å¼ï¼‰ | 9200 |
| **Milvus API** | `10.112.15.13:19530` | æ— è®¤è¯ | 19530 |
| **Milvus Web UI** | `http://10.112.15.13:9091` | æµè§ˆå™¨è®¿é—® | 9091 |

### æ–¹æ³• 1ï¼šç›´æ¥è¿æ¥ï¼ˆå†…ç½‘ IPï¼‰

**é€‚ç”¨åœºæ™¯ï¼š** å…¶ä»–ç”µè„‘å’ŒæœåŠ¡å™¨åœ¨åŒä¸€å†…ç½‘

**åœ¨å…¶ä»–ç”µè„‘ä¸Šçš„ Python è¿æ¥ç¤ºä¾‹ï¼š**

```python
# ============================================
# ä»¥ä¸‹ä»£ç åœ¨å…¶ä»–ç”µè„‘ä¸Šè¿è¡Œï¼ˆä¸æ˜¯åœ¨æœåŠ¡å™¨ä¸Šï¼ï¼‰
# ============================================

# MySQL è¿æ¥
import pymysql

conn = pymysql.connect(
    host='10.112.15.13',  # æœåŠ¡å™¨IP
    port=3306,
    user='rag_user',
    password='rag_password',  # ä»æœåŠ¡å™¨çš„ .env æ–‡ä»¶è·å–
    database='rag_data',
    charset='utf8mb4'
)

# Redis è¿æ¥
import redis

r = redis.Redis(
    host='10.112.15.13',  # æœåŠ¡å™¨IP
    port=6379,
    password='redis_secure_password',  # ä»æœåŠ¡å™¨çš„ .env æ–‡ä»¶è·å–
    decode_responses=True
)

# Elasticsearch è¿æ¥
from elasticsearch import Elasticsearch

es = Elasticsearch(['http://10.112.15.13:9200'])  # æœåŠ¡å™¨IP
print(es.info())

# Milvus è¿æ¥
from pymilvus import connections

connections.connect(
    alias="default",
    host='10.112.15.13',  # æœåŠ¡å™¨IP
    port=19530
)
```

**åœ¨å…¶ä»–ç”µè„‘ä¸Šçš„å‘½ä»¤è¡Œæµ‹è¯•ï¼š**

```bash
# ============================================
# ä»¥ä¸‹å‘½ä»¤åœ¨å…¶ä»–ç”µè„‘çš„ç»ˆç«¯æ‰§è¡Œï¼ˆä¸æ˜¯åœ¨æœåŠ¡å™¨ä¸Šï¼ï¼‰
# æ³¨æ„ï¼šä½¿ç”¨æœåŠ¡å™¨IP 10.112.15.13ï¼Œä¸æ˜¯ localhost
# ============================================

# æµ‹è¯• Redisï¼ˆåœ¨å…¶ä»–ç”µè„‘ä¸Šæ‰§è¡Œï¼‰
redis-cli -h 10.112.15.13 -p 6379 -a redis_secure_password ping
# é¢„æœŸè¾“å‡º: PONG

# æµ‹è¯• MySQLï¼ˆåœ¨å…¶ä»–ç”µè„‘ä¸Šæ‰§è¡Œï¼‰
mysql -h 10.112.15.13 -P 3306 -urag_user -p
# è¾“å…¥å¯†ç  rag_password

# æµ‹è¯• Elasticsearchï¼ˆåœ¨å…¶ä»–ç”µè„‘ä¸Šæ‰§è¡Œï¼‰
curl http://10.112.15.13:9200/_cluster/health?pretty
# é¢„æœŸè¾“å‡º: JSONæ ¼å¼çš„é›†ç¾¤å¥åº·ä¿¡æ¯

# æµ‹è¯• Milvusï¼ˆåœ¨å…¶ä»–ç”µè„‘ä¸Šæ‰§è¡Œï¼‰
curl http://10.112.15.13:19530/healthz
# é¢„æœŸè¾“å‡º: å¥åº·çŠ¶æ€ä¿¡æ¯

# åœ¨æµè§ˆå™¨æ‰“å¼€ Milvus Web UIï¼ˆåœ¨å…¶ä»–ç”µè„‘ä¸Šï¼‰
# è®¿é—®ï¼šhttp://10.112.15.13:9091
```

### æ–¹æ³• 2ï¼šSSH éš§é“ï¼ˆæ¨èï¼Œå®‰å…¨ï¼‰â­

**é€‚ç”¨åœºæ™¯ï¼š**
- éœ€è¦åŠ å¯†ä¼ è¾“ä¿æŠ¤æ•°æ®å®‰å…¨
- ç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³å®è·µ
- ä¸æƒ³ç›´æ¥æš´éœ²æ•°æ®åº“ç«¯å£

**å·¥ä½œåŸç†ï¼š**
```
å…¶ä»–ç”µè„‘(localhost:6379) <--SSHéš§é“--> æœåŠ¡å™¨(10.112.15.13:6379)
           â†‘                                      â†‘
    åœ¨å…¶ä»–ç”µè„‘ä¸Šè®¿é—®                         æœåŠ¡å™¨ä¸Šçš„Redis
    ä½¿ç”¨ localhost
```

#### 2.1 åœ¨å…¶ä»–ç”µè„‘ä¸Šå»ºç«‹ SSH éš§é“

**å•ä¸ªç«¯å£æ˜ å°„ç¤ºä¾‹ï¼š**

```bash
# ============================================
# ä»¥ä¸‹å‘½ä»¤åœ¨å…¶ä»–ç”µè„‘çš„ç»ˆç«¯æ‰§è¡Œï¼ˆä¸æ˜¯åœ¨æœåŠ¡å™¨ä¸Šï¼ï¼‰
# ============================================

# æ˜ å°„ MySQLï¼ˆå…¶ä»–ç”µè„‘çš„localhost:3306 â†’ æœåŠ¡å™¨çš„localhost:3306ï¼‰
ssh -L 3306:localhost:3306 yl@10.112.15.13 -N -f

# æ˜ å°„ Redis
ssh -L 6379:localhost:6379 yl@10.112.15.13 -N -f

# æ˜ å°„ Elasticsearch
ssh -L 9200:localhost:9200 yl@10.112.15.13 -N -f

# æ˜ å°„ Milvus API
ssh -L 19530:localhost:19530 yl@10.112.15.13 -N -f

# æ˜ å°„ Milvus Web UI
ssh -L 9091:localhost:9091 yl@10.112.15.13 -N -f
```

**ä¸€é”®æ˜ å°„æ‰€æœ‰ç«¯å£ï¼ˆæ¨èï¼‰ï¼š**

```bash
# ============================================
# åœ¨å…¶ä»–ç”µè„‘çš„ç»ˆç«¯æ‰§è¡Œè¿™ä¸€æ¡å‘½ä»¤å³å¯
# ============================================

ssh -L 3306:localhost:3306 \
    -L 6379:localhost:6379 \
    -L 9200:localhost:9200 \
    -L 9300:localhost:9300 \
    -L 19530:localhost:19530 \
    -L 9091:localhost:9091 \
    yl@10.112.15.13 -N -f

# è¾“å…¥æœåŠ¡å™¨SSHå¯†ç åï¼Œéš§é“ä¼šåœ¨åå°è¿è¡Œ
# æ³¨æ„ï¼šyl æ˜¯æœåŠ¡å™¨çš„SSHç”¨æˆ·åï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
```

**å‚æ•°è¯´æ˜ï¼š**
- `-L æœ¬åœ°ç«¯å£:è¿œç¨‹ä¸»æœº:è¿œç¨‹ç«¯å£`ï¼šç«¯å£è½¬å‘è§„åˆ™
- `-N`ï¼šä¸æ‰§è¡Œè¿œç¨‹å‘½ä»¤ï¼Œä»…è½¬å‘ç«¯å£
- `-f`ï¼šåå°è¿è¡Œ

#### 2.2 éªŒè¯éš§é“è¿æ¥

**åœ¨å…¶ä»–ç”µè„‘ä¸Šæµ‹è¯•ï¼ˆéš§é“å»ºç«‹åï¼‰ï¼š**

```bash
# ============================================
# SSHéš§é“å»ºç«‹åï¼Œåœ¨å…¶ä»–ç”µè„‘ä¸Šä½¿ç”¨ localhost è®¿é—®
# ä¸å†ä½¿ç”¨ 10.112.15.13ï¼Œå› ä¸ºéš§é“å·²ç»æ˜ å°„äº†ï¼
# ============================================

# æµ‹è¯• MySQLï¼ˆé€šè¿‡éš§é“ï¼Œä½¿ç”¨ localhostï¼‰
mysql -h localhost -P 3306 -urag_user -p
# è¾“å…¥å¯†ç ååº”èƒ½æ­£å¸¸è¿æ¥

# æµ‹è¯• Redisï¼ˆé€šè¿‡éš§é“ï¼Œä½¿ç”¨ localhostï¼‰
redis-cli -h localhost -p 6379 -a redis_secure_password ping
# é¢„æœŸè¾“å‡º: PONG

# æµ‹è¯• Elasticsearchï¼ˆé€šè¿‡éš§é“ï¼Œä½¿ç”¨ localhostï¼‰
curl http://localhost:9200/_cluster/health?pretty
# é¢„æœŸè¾“å‡º: é›†ç¾¤å¥åº·ä¿¡æ¯

# æµ‹è¯• Milvusï¼ˆé€šè¿‡éš§é“ï¼Œä½¿ç”¨ localhostï¼‰
curl http://localhost:19530/healthz
# é¢„æœŸè¾“å‡º: å¥åº·çŠ¶æ€

# åœ¨æµè§ˆå™¨æ‰“å¼€ Milvus Web UIï¼ˆé€šè¿‡éš§é“ï¼‰
# è®¿é—®ï¼šhttp://localhost:9091
```

#### 2.3 åœ¨å…¶ä»–ç”µè„‘ä¸Šçš„ Python ä»£ç è¿æ¥ï¼ˆéš§é“æ¨¡å¼ï¼‰

```python
# ============================================
# SSHéš§é“å»ºç«‹åï¼Œåœ¨å…¶ä»–ç”µè„‘ä¸Šè¿è¡Œè¿™æ®µä»£ç 
# æ³¨æ„ï¼šå…¨éƒ¨ä½¿ç”¨ localhostï¼Œä¸æ˜¯ 10.112.15.13
# ============================================

import pymysql
import redis
from elasticsearch import Elasticsearch
from pymilvus import connections

# MySQL è¿æ¥ï¼ˆé€šè¿‡ SSH éš§é“ï¼‰
conn = pymysql.connect(
    host='localhost',  # ä½¿ç”¨ localhostï¼
    port=3306,
    user='rag_user',
    password='rag_password',
    database='rag_data'
)

# Redis è¿æ¥ï¼ˆé€šè¿‡ SSH éš§é“ï¼‰
r = redis.Redis(
    host='localhost',  # ä½¿ç”¨ localhostï¼
    port=6379,
    password='redis_secure_password'
)

# Elasticsearch è¿æ¥ï¼ˆé€šè¿‡ SSH éš§é“ï¼‰
es = Elasticsearch(['http://localhost:9200'])  # ä½¿ç”¨ localhostï¼

# Milvus è¿æ¥ï¼ˆé€šè¿‡ SSH éš§é“ï¼‰
connections.connect(
    alias="default",
    host='localhost',  # ä½¿ç”¨ localhostï¼
    port=19530
)

print("æ‰€æœ‰æœåŠ¡è¿æ¥æˆåŠŸï¼")
```

#### 2.4 ç®¡ç† SSH éš§é“

**æŸ¥çœ‹éš§é“è¿›ç¨‹ï¼ˆåœ¨å…¶ä»–ç”µè„‘ä¸Šï¼‰ï¼š**

```bash
ps aux | grep "ssh -L"
```

**å…³é—­éš§é“ï¼ˆåœ¨å…¶ä»–ç”µè„‘ä¸Šï¼‰ï¼š**

```bash
# æŸ¥æ‰¾è¿›ç¨‹ ID
ps aux | grep "ssh -L" | grep -v grep

# å…³é—­æŒ‡å®šè¿›ç¨‹
kill <PID>

# å…³é—­æ‰€æœ‰ SSH éš§é“
pkill -f "ssh -L"
```

**è‡ªåŠ¨é‡è¿ï¼ˆä½¿ç”¨ autosshï¼‰ï¼š**

```bash
# åœ¨å…¶ä»–ç”µè„‘ä¸Šå®‰è£… autossh
sudo apt install autossh  # Ubuntu/Debian
sudo yum install autossh  # CentOS/RHEL

# ä½¿ç”¨ autosshï¼ˆè‡ªåŠ¨é‡è¿ï¼‰
autossh -M 0 -f -N \
    -L 3306:localhost:3306 \
    -L 6379:localhost:6379 \
    -L 9200:localhost:9200 \
    -L 19530:localhost:19530 \
    yl@10.112.15.13
```

### æ–¹æ³• 3ï¼šä½¿ç”¨ GUI å·¥å…·

#### MySQL ç®¡ç†å·¥å…·

**æ¨èå·¥å…·ï¼š**
- **MySQL Workbench**ï¼ˆå®˜æ–¹å·¥å…·ï¼Œå…è´¹ï¼‰
- **DataGrip**ï¼ˆJetBrains å‡ºå“ï¼ŒåŠŸèƒ½å¼ºå¤§ï¼‰
- **DBeaver**ï¼ˆå¼€æºï¼Œè·¨å¹³å°ï¼‰

**è¿æ¥é…ç½®ï¼ˆä»¥ MySQL Workbench ä¸ºä¾‹ï¼‰ï¼š**

**æ–¹å¼1ï¼šç›´æ¥è¿æ¥**
```
Connection Name: RAG Server MySQL
Connection Method: Standard (TCP/IP)
Hostname: 10.112.15.13
Port: 3306
Username: rag_user
Password: rag_password
Default Schema: rag_data
```

**æ–¹å¼2ï¼šé€šè¿‡ SSH éš§é“ï¼ˆæ¨èï¼‰**
```
Connection Name: RAG Server MySQL (SSH)
Connection Method: Standard TCP/IP over SSH

SSH é…ç½®ï¼š
  SSH Hostname: 10.112.15.13:22
  SSH Username: yl
  SSH Password: ä½ çš„SSHå¯†ç 

MySQL é…ç½®ï¼š
  MySQL Hostname: 127.0.0.1ï¼ˆé‡è¦ï¼ï¼‰
  MySQL Server Port: 3306
  Username: rag_user
  Password: rag_password
```

**é€šè¿‡ SSH éš§é“è¿æ¥ï¼ˆDataGripï¼‰ï¼š**

1. æ–°å»ºè¿æ¥ â†’ MySQL
2. SSH Tunnel æ ‡ç­¾é¡µ â†’ å¯ç”¨ "Use SSH tunnel"
3. å¡«å†™ SSH ä¿¡æ¯ï¼š
   - Host: 10.112.15.13
   - Port: 22
   - User: yl
   - Auth Type: Password
4. General æ ‡ç­¾é¡µï¼š
   - Host: localhostï¼ˆé‡è¦ï¼ï¼‰
   - Port: 3306
   - User: rag_user
   - Password: rag_password

#### Redis ç®¡ç†å·¥å…·

**æ¨èå·¥å…·ï¼š**
- **RedisInsight**ï¼ˆå®˜æ–¹å·¥å…·ï¼ŒåŠŸèƒ½å…¨é¢ï¼‰
- **Another Redis Desktop Manager**ï¼ˆå¼€æºï¼Œè½»é‡çº§ï¼‰

**è¿æ¥é…ç½®ï¼ˆRedisInsightï¼‰ï¼š**

**æ–¹å¼1ï¼šç›´æ¥è¿æ¥**
```
Host: 10.112.15.13
Port: 6379
Database Alias: RAG Server Redis
Password: redis_secure_password
```

**æ–¹å¼2ï¼šé€šè¿‡ SSH éš§é“**
```
å…ˆåœ¨å…¶ä»–ç”µè„‘å»ºç«‹SSHéš§é“ï¼š
ssh -L 6379:localhost:6379 yl@10.112.15.13 -N -f

ç„¶åè¿æ¥é…ç½®ï¼š
Host: localhost
Port: 6379
Database Alias: RAG Server Redis (SSH)
Password: redis_secure_password
```

#### Elasticsearch ç®¡ç†å·¥å…·

**æ¨èæ–¹å¼ï¼š**

1. **Kibana**ï¼ˆå®˜æ–¹å·¥å…·ï¼Œä½†éœ€è¦å•ç‹¬éƒ¨ç½²ï¼‰
2. **Elasticvue**ï¼ˆæµè§ˆå™¨æ’ä»¶ï¼Œè½»é‡ä¾¿æ·ï¼‰
3. **ç›´æ¥ API è®¿é—®**ï¼ˆä½¿ç”¨ curl æˆ– Postmanï¼‰

**Elasticvue Chrome æ’ä»¶å®‰è£…ï¼š**

```bash
# 1. è®¿é—® Chrome åº”ç”¨å•†åº—æœç´¢ "Elasticvue"
# 2. å®‰è£…æ’ä»¶åï¼Œæ·»åŠ è¿æ¥ï¼š
#    - Name: RAG Project ES
#    - Uri: http://æœåŠ¡å™¨IP:9200ï¼ˆæˆ– http://localhost:9200 + SSH éš§é“ï¼‰
```

**å¸¸ç”¨ API æ“ä½œï¼š**

```bash
# æŸ¥çœ‹é›†ç¾¤å¥åº·
curl http://localhost:9200/_cluster/health?pretty

# æŸ¥çœ‹æ‰€æœ‰ç´¢å¼•
curl http://localhost:9200/_cat/indices?v

# åˆ›å»ºç´¢å¼•
curl -X PUT "http://localhost:9200/documents" -H 'Content-Type: application/json' -d'
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 0
  }
}
'

# æœç´¢æ–‡æ¡£
curl -X GET "http://localhost:9200/documents/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match_all": {}
  }
}
'
```

#### Milvus ç®¡ç†å·¥å…·

**Attuï¼ˆå®˜æ–¹ Web UIï¼‰ï¼š**

Milvus å·²å†…ç½® Web UIï¼Œå¯ç›´æ¥è®¿é—®ï¼š

```
æµè§ˆå™¨æ‰“å¼€: http://æœåŠ¡å™¨IP:9091
ï¼ˆæˆ–é€šè¿‡ SSH éš§é“: http://localhost:9091ï¼‰
```

**ä½¿ç”¨ Docker è¿è¡Œç‹¬ç«‹çš„ Attuï¼š**

```bash
docker run -d -p 8000:3000 \
  -e MILVUS_URL=æœåŠ¡å™¨IP:19530 \
  zilliz/attu:latest

# è®¿é—® http://localhost:8000
```

---

## æœªæ¥åŠŸèƒ½é›†æˆæŒ‡å—

### Redis é›†æˆç¤ºä¾‹

#### 1. ç¼“å­˜å±‚ï¼ˆè£…é¥°å™¨æ¨¡å¼ï¼‰

**å®‰è£…ä¾èµ–ï¼š**

```bash
pip install redis
```

**å®ç°ç¼“å­˜è£…é¥°å™¨ï¼š**

```python
# app/utils/cache.py
import redis
import json
import functools
from typing import Callable, Any
from app.core.config import settings

# è¿æ¥ Redis
redis_client = redis.Redis(
    host=settings.REDIS_HOST,
    port=settings.REDIS_PORT,
    password=settings.REDIS_PASSWORD,
    decode_responses=True
)

def cache_result(expire_time: int = 3600):
    """
    ç¼“å­˜å‡½æ•°ç»“æœè£…é¥°å™¨

    Args:
        expire_time: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 1 å°æ—¶
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"

            # å°è¯•ä»ç¼“å­˜è·å–
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = func(*args, **kwargs)
            redis_client.setex(
                cache_key,
                expire_time,
                json.dumps(result, ensure_ascii=False)
            )
            return result

        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@cache_result(expire_time=1800)  # ç¼“å­˜ 30 åˆ†é’Ÿ
def get_document_by_id(doc_id: int):
    # ä»æ•°æ®åº“æŸ¥è¯¢ï¼ˆæ…¢æ“ä½œï¼‰
    return db.query(Document).filter(Document.id == doc_id).first()
```

#### 2. ä¼šè¯ç®¡ç†

```python
# app/utils/session.py
import uuid
from datetime import timedelta

class RedisSession:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.prefix = "session:"

    def create_session(self, user_id: int, expire_hours: int = 24) -> str:
        """åˆ›å»ºç”¨æˆ·ä¼šè¯"""
        session_id = str(uuid.uuid4())
        session_key = f"{self.prefix}{session_id}"

        self.redis.hset(session_key, mapping={
            "user_id": user_id,
            "created_at": datetime.now().isoformat()
        })
        self.redis.expire(session_key, timedelta(hours=expire_hours))

        return session_id

    def get_session(self, session_id: str) -> dict:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        session_key = f"{self.prefix}{session_id}"
        return self.redis.hgetall(session_key)

    def delete_session(self, session_id: str):
        """åˆ é™¤ä¼šè¯ï¼ˆç™»å‡ºï¼‰"""
        session_key = f"{self.prefix}{session_id}"
        self.redis.delete(session_key)
```

#### 3. ä»»åŠ¡é˜Ÿåˆ—ï¼ˆä½¿ç”¨ Celeryï¼‰

```bash
# å®‰è£… Celery
pip install celery[redis]
```

```python
# app/tasks/celery_app.py
from celery import Celery
from app.core.config import settings

celery_app = Celery(
    'rag_tasks',
    broker=f'redis://:{settings.REDIS_PASSWORD}@{settings.REDIS_HOST}:{settings.REDIS_PORT}/0',
    backend=f'redis://:{settings.REDIS_PASSWORD}@{settings.REDIS_HOST}:{settings.REDIS_PORT}/1'
)

# å®šä¹‰å¼‚æ­¥ä»»åŠ¡
@celery_app.task
def process_document_async(file_path: str):
    """å¼‚æ­¥å¤„ç†æ–‡æ¡£ä¸Šä¼ å’Œå‘é‡åŒ–"""
    # 1. è¯»å–æ–‡æ¡£
    # 2. å‘é‡åŒ–
    # 3. å­˜å‚¨åˆ° Milvus
    # 4. æ›´æ–° MySQL çŠ¶æ€
    return {"status": "completed", "file": file_path}

# ä½¿ç”¨ç¤ºä¾‹
# from app.tasks.celery_app import process_document_async
# task = process_document_async.delay("/path/to/document.pdf")
# result = task.get(timeout=60)
```

### Elasticsearch é›†æˆç¤ºä¾‹

#### 1. å…¨æ–‡æœç´¢ API

**å®‰è£…ä¾èµ–ï¼š**

```bash
pip install elasticsearch llama-index-vector-stores-elasticsearch
```

**åˆå§‹åŒ– Elasticsearchï¼š**

```python
# app/core/elasticsearch_client.py
from elasticsearch import Elasticsearch
from app.core.config import settings

es_client = Elasticsearch(
    [f'http://{settings.ES_HOST}:{settings.ES_PORT}']
)

# åˆ›å»ºæ–‡æ¡£ç´¢å¼•
def create_document_index():
    index_body = {
        "settings": {
            "number_of_shards": 1,
            "number_of_replicas": 0,
            "analysis": {
                "analyzer": {
                    "ik_analyzer": {
                        "type": "custom",
                        "tokenizer": "ik_max_word"
                    }
                }
            }
        },
        "mappings": {
            "properties": {
                "title": {
                    "type": "text",
                    "analyzer": "ik_analyzer"
                },
                "content": {
                    "type": "text",
                    "analyzer": "ik_analyzer"
                },
                "file_path": {
                    "type": "keyword"
                },
                "upload_time": {
                    "type": "date"
                }
            }
        }
    }

    if not es_client.indices.exists(index="documents"):
        es_client.indices.create(index="documents", body=index_body)
```

#### 2. æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å…¨æ–‡ï¼‰

```python
# app/services/hybrid_search.py
from typing import List, Dict
from llama_index.core import VectorStoreIndex
from elasticsearch import Elasticsearch

class HybridSearchService:
    def __init__(self, vector_index: VectorStoreIndex, es_client: Elasticsearch):
        self.vector_index = vector_index
        self.es = es_client

    def search(self, query: str, top_k: int = 10) -> List[Dict]:
        """
        æ··åˆæ£€ç´¢ï¼šç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…¨æ–‡åŒ¹é…

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            æ’åºåçš„æ··åˆç»“æœ
        """
        # 1. å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
        vector_results = self.vector_index.as_query_engine().query(query)

        # 2. å…¨æ–‡æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
        es_results = self.es.search(
            index="documents",
            body={
                "query": {
                    "multi_match": {
                        "query": query,
                        "fields": ["title^2", "content"],
                        "type": "best_fields"
                    }
                },
                "size": top_k
            }
        )

        # 3. ç»“æœèåˆï¼ˆRRF - Reciprocal Rank Fusionï¼‰
        combined_results = self._merge_results(
            vector_results,
            es_results['hits']['hits'],
            top_k
        )

        return combined_results

    def _merge_results(self, vector_res, es_res, top_k):
        """èåˆä¸¤ç§æ£€ç´¢ç»“æœ"""
        # å®ç° RRF ç®—æ³•æˆ–ç®€å•çš„æƒé‡èåˆ
        # ...
        pass
```

#### 3. ä¸ LlamaIndex é›†æˆ

```python
# app/rag/hybrid_retriever.py
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.elasticsearch import ElasticsearchStore

# ä½¿ç”¨ Elasticsearch ä½œä¸ºå‘é‡å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
es_vector_store = ElasticsearchStore(
    es_url=f"http://{settings.ES_HOST}:{settings.ES_PORT}",
    index_name="llama_index_vectors"
)

vector_index = VectorStoreIndex.from_vector_store(es_vector_store)
query_engine = vector_index.as_query_engine()

# æŸ¥è¯¢
response = query_engine.query("å¦‚ä½•éƒ¨ç½² Docker æœåŠ¡ï¼Ÿ")
print(response)
```

### ä¾èµ–åŒ…å®‰è£…

**å°†ä»¥ä¸‹ä¾èµ–æ·»åŠ åˆ° `requirements.txt`ï¼š**

```txt
# Redis ç›¸å…³
redis>=5.0.0
celery[redis]>=5.3.0

# Elasticsearch ç›¸å…³
elasticsearch>=8.11.0
llama-index-vector-stores-elasticsearch
```

**å®‰è£…ï¼š**

```bash
pip install -r requirements.txt
```

---

## æ•°æ®æŒä¹…åŒ–å’Œå¤‡ä»½

### Docker Volume ç®¡ç†

**æŸ¥çœ‹æ‰€æœ‰å·ï¼š**

```bash
docker volume ls | grep rag
```

**æŸ¥çœ‹å·è¯¦æƒ…ï¼š**

```bash
docker volume inspect rag_project_mysql_data
docker volume inspect rag_project_redis_data
docker volume inspect rag_project_es_data
```

**å·å­˜å‚¨ä½ç½®ï¼ˆé»˜è®¤ï¼‰ï¼š**

```
/var/lib/docker/volumes/rag_project_mysql_data/_data
/var/lib/docker/volumes/rag_project_redis_data/_data
/var/lib/docker/volumes/rag_project_es_data/_data
/var/lib/docker/volumes/rag_project_milvus_data/_data
```

### å¤‡ä»½ç­–ç•¥

#### MySQL å¤‡ä»½

**æ‰‹åŠ¨å¤‡ä»½ï¼š**

```bash
# å¤‡ä»½å•ä¸ªæ•°æ®åº“
docker exec rag_mysql mysqldump -uroot -p"$(grep DB_ROOT_PASSWORD .env | cut -d'=' -f2)" rag_data > backup_$(date +%Y%m%d_%H%M%S).sql

# å¤‡ä»½æ‰€æœ‰æ•°æ®åº“
docker exec rag_mysql mysqldump -uroot -p"$(grep DB_ROOT_PASSWORD .env | cut -d'=' -f2)" --all-databases > backup_all_$(date +%Y%m%d).sql
```

**æ¢å¤å¤‡ä»½ï¼š**

```bash
# æ¢å¤æ•°æ®åº“
docker exec -i rag_mysql mysql -uroot -p"$(grep DB_ROOT_PASSWORD .env | cut -d'=' -f2)" rag_data < backup_20231218.sql
```

**è‡ªåŠ¨å¤‡ä»½è„šæœ¬ï¼š**

```bash
#!/bin/bash
# backup_mysql.sh

BACKUP_DIR="/path/to/backups/mysql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
DB_PASSWORD=$(grep DB_ROOT_PASSWORD .env | cut -d'=' -f2)

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å¤‡ä»½æ•°æ®åº“
docker exec rag_mysql mysqldump -uroot -p"$DB_PASSWORD" rag_data > "$BACKUP_DIR/rag_data_$TIMESTAMP.sql"

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
gzip "$BACKUP_DIR/rag_data_$TIMESTAMP.sql"

# åˆ é™¤ 7 å¤©å‰çš„å¤‡ä»½
find $BACKUP_DIR -name "*.sql.gz" -mtime +7 -delete

echo "Backup completed: rag_data_$TIMESTAMP.sql.gz"
```

**è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼ˆæ¯å¤©å‡Œæ™¨ 2 ç‚¹ï¼‰ï¼š**

```bash
# ç¼–è¾‘ crontab
crontab -e

# æ·»åŠ å®šæ—¶ä»»åŠ¡
0 2 * * * /path/to/backup_mysql.sh >> /var/log/mysql_backup.log 2>&1
```

#### Redis å¤‡ä»½

**Redis è‡ªåŠ¨ç”Ÿæˆå¤‡ä»½æ–‡ä»¶ï¼ˆAOF æ¨¡å¼ï¼‰ï¼š**

```bash
# å¤‡ä»½ Redis æ•°æ®æ–‡ä»¶
docker exec rag_redis redis-cli -a "$(grep REDIS_PASSWORD .env | cut -d'=' -f2)" SAVE

# å¤åˆ¶å¤‡ä»½æ–‡ä»¶
docker cp rag_redis:/data/appendonly.aof ./redis_backup_$(date +%Y%m%d).aof
```

#### Elasticsearch å¤‡ä»½ï¼ˆå¿«ç…§ï¼‰

```bash
# åˆ›å»ºå¿«ç…§ä»“åº“
curl -X PUT "http://localhost:9200/_snapshot/my_backup" -H 'Content-Type: application/json' -d'
{
  "type": "fs",
  "settings": {
    "location": "/usr/share/elasticsearch/backup"
  }
}
'

# åˆ›å»ºå¿«ç…§
curl -X PUT "http://localhost:9200/_snapshot/my_backup/snapshot_$(date +%Y%m%d)"
```

---

## å¸¸è§é—®é¢˜

### 1. ç«¯å£å†²çª

**ç°è±¡ï¼š**
```
Error: bind: address already in use
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æŸ¥çœ‹ç«¯å£å ç”¨æƒ…å†µ
sudo lsof -i :3306
sudo lsof -i :6379
sudo lsof -i :9200

# ä¿®æ”¹ .env æ–‡ä»¶ï¼Œæ›´æ”¹ç«¯å£
DB_PORT=13306
REDIS_PORT=16379
ES_PORT=19200

# é‡æ–°å¯åŠ¨æœåŠ¡
docker-compose down
docker-compose up -d
```

### 2. Elasticsearch å¯åŠ¨å¤±è´¥

**ç°è±¡ï¼š**
```
max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# ä¸´æ—¶ä¿®æ”¹ï¼ˆé‡å¯åå¤±æ•ˆï¼‰
sudo sysctl -w vm.max_map_count=262144

# æ°¸ä¹…ä¿®æ”¹
echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

### 3. Elasticsearch å†…å­˜ä¸è¶³

**ç°è±¡ï¼š**
å®¹å™¨é¢‘ç¹é‡å¯ï¼Œæ—¥å¿—æ˜¾ç¤º OutOfMemoryError

**è§£å†³æ–¹æ¡ˆï¼š**

ä¿®æ”¹ `docker-compose.yml` ä¸­çš„å†…å­˜é…ç½®ï¼š

```yaml
elasticsearch:
  environment:
    - "ES_JAVA_OPTS=-Xms256m -Xmx256m"  # é™ä½åˆ° 256MB
```

### 4. å®¹å™¨æ— æ³•è®¿é—®ç½‘ç»œ

**ç°è±¡ï¼š**
```
Could not resolve host: docker.elastic.co
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥ DNS é…ç½®
docker run --rm busybox nslookup google.com

# ä¿®æ”¹ Docker å®ˆæŠ¤è¿›ç¨‹é…ç½®
sudo vim /etc/docker/daemon.json

# æ·»åŠ  DNS æœåŠ¡å™¨
{
  "dns": ["8.8.8.8", "8.8.4.4"]
}

# é‡å¯ Docker
sudo systemctl restart docker
```

### 5. é˜²ç«å¢™é…ç½®ï¼ˆå¦‚éœ€å¤–ç½‘è®¿é—®ï¼‰

**Ubuntu/Debianï¼ˆufwï¼‰ï¼š**

```bash
sudo ufw allow 3306/tcp
sudo ufw allow 6379/tcp
sudo ufw allow 9200/tcp
sudo ufw allow 19530/tcp
sudo ufw reload
```

**CentOS/RHELï¼ˆfirewalldï¼‰ï¼š**

```bash
sudo firewall-cmd --permanent --add-port=3306/tcp
sudo firewall-cmd --permanent --add-port=6379/tcp
sudo firewall-cmd --permanent --add-port=9200/tcp
sudo firewall-cmd --permanent --add-port=19530/tcp
sudo firewall-cmd --reload
```

### 6. Redis å¯†ç è®¤è¯å¤±è´¥

**ç°è±¡ï¼š**
```
NOAUTH Authentication required
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥ .env ä¸­çš„å¯†ç æ˜¯å¦æ­£ç¡®
grep REDIS_PASSWORD .env

# æµ‹è¯•è¿æ¥
docker exec rag_redis redis-cli -a "your_password" ping
```

### 7. MySQL å­—ç¬¦é›†é—®é¢˜ï¼ˆä¸­æ–‡ä¹±ç ï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥å­—ç¬¦é›†é…ç½®
docker exec rag_mysql mysql -uroot -p -e "SHOW VARIABLES LIKE 'character%'"

# åº”æ˜¾ç¤º utf8mb4ï¼Œå¦‚æœä¸æ˜¯ï¼Œé‡æ–°åˆ›å»ºæ•°æ®åº“
docker exec rag_mysql mysql -uroot -p -e "
ALTER DATABASE rag_data CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci;
"
```

---

## æœåŠ¡ç®¡ç†å‘½ä»¤

### åŸºæœ¬æ“ä½œ

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# å¯åŠ¨æŒ‡å®šæœåŠ¡
docker-compose up -d redis elasticsearch

# åœæ­¢æ‰€æœ‰æœåŠ¡
docker-compose stop

# åœæ­¢æŒ‡å®šæœåŠ¡
docker-compose stop redis

# é‡å¯æœåŠ¡
docker-compose restart redis

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker-compose logs -f redis

# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# è¿›å…¥å®¹å™¨
docker exec -it rag_redis sh
docker exec -it rag_mysql bash
```

### æ¸…ç†æ“ä½œ

```bash
# åœæ­¢å¹¶åˆ é™¤å®¹å™¨ï¼ˆä¿ç•™æ•°æ®å·ï¼‰
docker-compose down

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨å’Œæ•°æ®å·ï¼ˆå±é™©æ“ä½œï¼ï¼‰
docker-compose down -v

# åˆ é™¤æœªä½¿ç”¨çš„é•œåƒ
docker image prune -a

# åˆ é™¤æœªä½¿ç”¨çš„å·
docker volume prune

# å®Œå…¨æ¸…ç† Docker ç³»ç»Ÿ
docker system prune -a --volumes
```

### èµ„æºç›‘æ§

```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ
docker stats

# æŸ¥çœ‹ç‰¹å®šå®¹å™¨
docker stats rag_redis rag_elasticsearch

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨
df -h | grep docker

# æŸ¥çœ‹å·ä½¿ç”¨æƒ…å†µ
docker system df -v
```

### æ—¥å¿—ç®¡ç†

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f --tail=100 redis

# å¯¼å‡ºæ—¥å¿—åˆ°æ–‡ä»¶
docker-compose logs redis > redis.log

# æ¸…ç†æ—¥å¿—ï¼ˆéœ€è¦é‡å¯å®¹å™¨ï¼‰
docker-compose down
docker-compose up -d
```

---

## æ€§èƒ½è°ƒä¼˜å»ºè®®

### å¼€å‘ç¯å¢ƒ

- Elasticsearch å†…å­˜ï¼š512MBï¼ˆå½“å‰é…ç½®ï¼‰
- Redis æ— éœ€é¢å¤–é…ç½®
- MySQL è¿æ¥æ± ï¼š20-50 è¿æ¥

### ç”Ÿäº§ç¯å¢ƒ

1. **å¯ç”¨ Elasticsearch å®‰å…¨è®¤è¯**
   ```yaml
   environment:
     - xpack.security.enabled=true
     - ELASTIC_PASSWORD=your_strong_password
   ```

2. **ä½¿ç”¨å¼ºå¯†ç **ï¼ˆMySQLã€Redisï¼‰

3. **é…ç½®èµ„æºé™åˆ¶**
   ```yaml
   services:
     elasticsearch:
       deploy:
         resources:
           limits:
             cpus: '2.0'
             memory: 2G
           reservations:
             memory: 1G
   ```

4. **å®šæœŸå¤‡ä»½æ•°æ®**

5. **ç›‘æ§ç£ç›˜ç©ºé—´**
   ```bash
   df -h | grep docker
   ```

6. **ä½¿ç”¨æ—¥å¿—è½®è½¬**
   ```json
   // /etc/docker/daemon.json
   {
     "log-driver": "json-file",
     "log-opts": {
       "max-size": "10m",
       "max-file": "3"
     }
   }
   ```

---

## æ•…éšœæ’æŸ¥

### æœåŠ¡æ— æ³•å¯åŠ¨

1. æŸ¥çœ‹æ—¥å¿—ï¼š`docker-compose logs <service_name>`
2. æ£€æŸ¥ç«¯å£å ç”¨ï¼š`sudo lsof -i :<port>`
3. éªŒè¯é…ç½®ï¼š`docker-compose config`
4. æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼š`df -h`

### è¿æ¥è¶…æ—¶

1. æ£€æŸ¥é˜²ç«å¢™ï¼š`sudo ufw status`
2. éªŒè¯ç½‘ç»œï¼š`docker network ls`
3. æµ‹è¯•è¿æ¥ï¼š`telnet æœåŠ¡å™¨IP ç«¯å£`

### æ€§èƒ½é—®é¢˜

1. æŸ¥çœ‹èµ„æºä½¿ç”¨ï¼š`docker stats`
2. æ£€æŸ¥æ…¢æŸ¥è¯¢æ—¥å¿—ï¼ˆMySQLï¼‰
3. åˆ†æ Elasticsearch ç´¢å¼•çŠ¶æ€
4. ä¼˜åŒ– Milvus ç´¢å¼•å‚æ•°

---

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š

- æäº¤ Issueï¼š[é¡¹ç›® GitHub Issues]
- é‚®ä»¶è”ç³»ï¼š[your-email@example.com]
- æŸ¥çœ‹æ–‡æ¡£ï¼š[é¡¹ç›®æ–‡æ¡£é“¾æ¥]

---

## ç‰ˆæœ¬å†å²

- **v1.0.0** (2023-12-18)
  - âœ… åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
  - âœ… MySQL 8.0 + Milvus 2.3.13 éƒ¨ç½²
  - âœ… Redis 7.2 + Elasticsearch 8.11 æ”¯æŒ
  - âœ… å®Œæ•´çš„ SSH éš§é“è®¿é—®æŒ‡å—
  - âœ… æœªæ¥åŠŸèƒ½é›†æˆç¤ºä¾‹

---

**æœ€åæ›´æ–°æ—¶é—´ï¼š** 2023å¹´12æœˆ18æ—¥
