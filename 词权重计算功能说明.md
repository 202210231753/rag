# ✅ 词权重计算接口说明（IDF）

本模块提供两类能力：

1) **人工配置词权重**：对指定词条写入人工权重（用于干预排序）。
2) **自动计算权重**：基于语料库使用 **IDF（逆文档频率）** 全量计算权重，并写入数据库（不会覆盖人工权重）。

---

## 1. 数据表

### 1.1 `corpus_documents`（语料/问答历史）
- 作用：作为 IDF 计算的“文档集合”。
- 字段：
  - `id`：主键
  - `content`：文档内容（Text）
  - `created_at`：创建时间
- 代码位置：`app/models/term_weight.py`

### 1.2 `term_weights`（词权重）
- 作用：保存词条权重，供后续 query 解析/排序使用。
- 字段：
  - `term`：词条（唯一）
  - `weight`：权重值
  - `source`：来源（`MANUAL`/`AUTO`）
  - `updated_at`：更新时间
- 代码位置：`app/models/term_weight.py`

> 说明：项目当前未引入迁移工具，因此在服务初始化时通过 `Base.metadata.create_all(...)` 做“按需建表”（与 tokenizer 模块一致）。

---

## 2. 接口

### 2.1 人工配置词权重
- 方法：`POST`
- 路径：`/api/v1/tokenizer/term-weight`
- Body：
  - `term` (String，必填)：目标词条
  - `weight` (Float，必填，`>=0`)：权重值
- Response：
```json
{"code":200,"msg":"success","data":{"success":true}}
```
- 实现位置：
  - 路由：`app/api/v1/endpoints/tokenizer.py`
  - 服务：`app/services/term_weight_service.py`

行为说明：
- 如果该词条不存在：插入 `term_weights(term, weight, source=MANUAL)`
- 如果已存在：更新权重并将 `source` 置为 `MANUAL`

### 2.2 自动计算权重（IDF）
- 方法：`POST`
- 路径：`/api/v1/tokenizer/term-weight/auto`
- Body：无
- Response：
```json
{"code":200,"msg":"success","data":{"success":true}}
```
- 实现位置：
  - 路由：`app/api/v1/endpoints/tokenizer.py`
  - 服务：`app/services/term_weight_service.py`

前置条件：
- `corpus_documents` 至少存在 1 条文档；否则返回 400（语料为空）。

---

## 3. 自动权重算法（IDF + 噪音清洗 + 归一化）

### 3.1 文档总数 N
- `N = count(corpus_documents)`

### 3.2 df 统计（包含该词的文档数）
- 遍历每条 `corpus_documents.content`，调用当前分词器分词：
  - 优先使用 `TokenizerManager.tokenize`
  - 若分词失败（例如 HanLP 模型不可用），fallback 到 `JiebaTokenizer`
- 对每个文档取词条集合 `unique_terms`，更新频率表：
  - `df(term) += 1`

### 3.3 噪音清洗
当前实现的过滤规则：
- token 为空/全空白：过滤
- token 长度 `<= 1`：过滤
- token 全数字：过滤
- 停用词：过滤（内置少量中文停用词集）
- df 过低：过滤（默认 `min_df=2`）

对应代码：`app/services/term_weight_service.py`

### 3.4 权重计算
对每个词条 `t`：

```
Weight(t) = log10( N / (df(t) + 1) )
```

### 3.5 归一化（Min-Max）
对所有 `Weight(t)` 做 min-max 归一化到 `[0, 1]`：
- `w_norm = (w - min_w) / (max_w - min_w)`
- 若 `max_w == min_w`：全部置为 `1.0`

### 3.6 写库策略（保留人工权重）
- 若 `term_weights.source == MANUAL`：不覆盖
- 否则写入/更新为 `AUTO`

---

## 4. 如何写入测试语料（示例 SQL）

```sql
INSERT INTO corpus_documents(content) VALUES
('AI手机是核心产品，支持大模型与RAG问答'),
('手机影像算法提升明显，AI能力增强'),
('RAG系统需要分词、召回与重排序');
```

然后调用：`POST /api/v1/tokenizer/term-weight/auto` 触发计算。

