# test_env_async.py
import os
import logging
import sys
import asyncio
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(stream=sys.stdout, level=logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

from llama_index.core import VectorStoreIndex, Document, StorageContext
from llama_index.vector_stores.milvus import MilvusVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI

# ç¡®ä¿ä½ æœ‰ OPENAI_API_KEY
if not os.getenv("OPENAI_API_KEY"):
    print("âŒ é”™è¯¯: è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")
    exit(1)

async def test_rag_async():
    print("ğŸš€ å¼€å§‹å¼‚æ­¥æµ‹è¯• LlamaIndex + Milvus ç¯å¢ƒ...")
    
    # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
    doc = Document(text="FastAPI æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„ Web æ¡†æ¶ï¼Œå¹¶è¡Œå¼€å‘æ•ˆç‡å¾ˆé«˜ã€‚")
    print("âœ… æ¨¡æ‹Ÿæ–‡æ¡£åˆ›å»ºæˆåŠŸ")
    
    # 2. è¿æ¥ Milvus
    vector_store = MilvusVectorStore(
        uri="http://localhost:19530",
        collection_name="test_collection",
        dim=1536,
        overwrite=True
    )
    print("âœ… MilvusVectorStore åˆå§‹åŒ–æˆåŠŸ")
    
    # 3. åˆ›å»ºå­˜å‚¨ä¸Šä¸‹æ–‡
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    
    # 4. ç”Ÿæˆç´¢å¼•
    print("â³ æ­£åœ¨è°ƒç”¨ OpenAI Embedding å¹¶å­˜å…¥ Milvus...")
    index = VectorStoreIndex.from_documents(
        [doc], 
        storage_context=storage_context
    )
    print("âœ… ç´¢å¼•æ„å»ºæˆåŠŸï¼æ•°æ®å·²å­˜å…¥ Milvus")
    
    # 5. æµ‹è¯•æŸ¥è¯¢
    query_engine = index.as_query_engine()
    response = await query_engine.aquery("FastAPI çš„ä¼˜ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ")  # ä½¿ç”¨å¼‚æ­¥æŸ¥è¯¢
    print(f"\nğŸ¤– å›ç­”ç»“æœ: {response}\n")

if __name__ == "__main__":
    try:
        asyncio.run(test_rag_async())
        print("ğŸ‰ æ­å–œï¼å¼‚æ­¥ç¯å¢ƒé…ç½®å®Œç¾ï¼Œæ²¡æœ‰ç‰ˆæœ¬å†²çªã€‚")
    except Exception as e:
        print(f"\nâŒ å¼‚æ­¥ç¯å¢ƒæµ‹è¯•å¤±è´¥: {e}")
