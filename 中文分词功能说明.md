# 中文分词模块（query 解析）功能说明

本模块用于对用户 query 进行中文分词，并提供专用词条（自定义词库）管理能力。实现目标：

- 支持专用词条管理：单条增删、文件批量增删
- 支持两种以上分词器可选，并可在运行时切换

## 1. 模块位置与路由

- 路由挂载：`app/api/v1/router.py`
- 接口前缀：`/api/v1/tokenizer`
- 模块实现：
  - API：`app/api/v1/endpoints/tokenizer.py`
  - Service：`app/services/tokenizer_service.py`
  - 分词内核：`app/tokenizer/`
  - Schema：`app/schemas/tokenizer_schema.py`

## 2. 支持的分词器

当前内置两个分词器（可通过接口切换）：

- `jieba`：经典中文分词；适合通用场景
- `hanlp`：HanLP 预训练分词模型；需要本地已安装 `hanlp` 且模型文件可用（常见情况为首次使用会下载模型）

说明：
- 专用词条来自自定义词库，始终优先输出为整体 token（与分词器解耦）
- 对非词条片段，再交给当前分词器（jieba/HanLP）切分

依赖提示：
- 当前环境若未安装对应依赖（`jieba` / `hanlp`），接口切换会返回 400

## 3. 专用词条（自定义词库）管理

### 3.1 存储与持久化

模块使用 MySQL 持久化（SQLAlchemy），进程重启后仍生效：

- 分词器配置表：`tokenizer_config`（单行配置，id=1）
- 词库表：`tokenizer_terms`（唯一词条 term）

表模型定义：
- `app/models/tokenizer.py`

### 3.2 词条规则

- 空行会被忽略/计为失败（批量）
- 词条增删为幂等操作：
  - `ADD` 已存在词条：记为成功，不重复写入
  - `DELETE` 不存在词条：记为成功，不报错

## 4. 接口定义

所有接口统一返回结构：

```json
{
  "code": 200,
  "msg": "success",
  "data": {}
}
```

### 4.1 分词器选择

- **Method**：`POST`
- **URL**：`/api/v1/tokenizer/select`
- **Body**：

| 参数名 | 类型 | 必填 | 示例 | 说明 |
| --- | --- | --- | --- | --- |
| `tokenizerId` | String | 是 | `"jieba"` | 分词器唯一标识ID |

- **Response**：

```json
{
  "code": 200,
  "msg": "success",
  "data": { "success": true }
}
```

### 4.2 专用词条的增删（单条）

- **Method**：`POST`
- **URL**：`/api/v1/tokenizer/term`
- **Body**：

| 参数名 | 类型 | 必填 | 示例 | 说明 |
| --- | --- | --- | --- | --- |
| `term` | String | 是 | `"遥遥领先"` | 目标词条 |
| `operation` | String | 是 | `"ADD"` | 操作类型：ADD(新增), DELETE(删除) |

- **Response**：

```json
{
  "code": 200,
  "msg": "success",
  "data": { "success": true }
}
```

### 4.3 专用词条的批量增删（文件上传）

- **Method**：`POST`
- **URL**：`/api/v1/tokenizer/terms/batch`
- **Content-Type**：`multipart/form-data`
- **Form**：

| 参数名 | 类型 | 必填 | 示例 | 说明 |
| --- | --- | --- | --- | --- |
| `file` | File | 是 | `terms.txt` | 包含词条列表的文本文件（UTF-8，一行一个） |
| `operation` | String | 是 | `"ADD"` | 批量操作类型：ADD(新增), DELETE(删除) |

- **Response**：

```json
{
  "code": 200,
  "msg": "success",
  "data": {
    "successCount": 500,
    "failCount": 2
  }
}
```

## 5. 运行与验证（示例）

启动后访问 Swagger：
- `http://localhost:8000/docs`

接口调用示例（curl）：

- 切换分词器
  - `curl -X POST "http://localhost:8000/api/v1/tokenizer/select" -H "Content-Type: application/json" -d '{"tokenizerId":"hanlp"}'`
- 单条新增词条
  - `curl -X POST "http://localhost:8000/api/v1/tokenizer/term" -H "Content-Type: application/json" -d '{"term":"遥遥领先","operation":"ADD"}'`
- 批量新增词条
  - `curl -X POST "http://localhost:8000/api/v1/tokenizer/terms/batch" -F "operation=ADD" -F "file=@terms.txt"`
